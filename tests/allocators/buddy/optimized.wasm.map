{"version":3,"sources":["~lib/allocator/buddy.ts","~lib/memory.ts"],"names":[],"mappings":"mPCmPE,AAAI,AAAC,KAAG,EACR,AAAU,EAAM,KAChB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EAEZ,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EACZ,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EAWZ,AAPA,EADA,AAAe,EAAC,GAAO,QAKvB,AAAe,AAAgB,iBAI/B,AAAW,EANX,AADA,EAAK,GACA,MAMiB,GAAG,KACzB,AAAI,EAAK,KAAG,EACZ,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAG,KACzB,AAAI,EAAK,KAAI,EACb,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAI1B,EADA,AAAI,AAAK,AAAC,EAAO,GAAb,QAEJ,EAAK,KAGL,AAAe,GAAW,AAAC,GAAY,QAChC,EAAK,KACV,AAAW,EAAM,KACjB,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,EAAK,KACL,EAAQ,aA9RR,AAAO,EAAM,EAAG,WAgDN,AAAC,EAAM,KAAZ,KACK,SAAV,EAA2B,WAAT,SAClB,WAIF,AAAI,AAAC,EAAO,QACH,EAAK,KACV,AAAW,EAAW,AAAU,QAChC,AAAW,EAAQ,GAAG,AAAU,EAAO,SACvC,AAAW,EAAQ,GAAG,AAAU,EAAO,SACvC,AAAW,EAAO,GAAI,AAAU,EAAM,SACtC,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,AAAI,EAAI,KACN,AAAW,EAAU,AAAU,QAC/B,AAAW,EAAO,GAAG,AAAU,EAAM,SACrC,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACN,AAAW,EAAM,AAAU,QAC3B,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACN,AAAW,EAAM,AAAU,QAC3B,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACI,IADD,EACkB,MAAT,UAEpB,EAKF,AAAI,EAAK,KAAI,UACH,EAAO,gBAGX,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,EAAK,GAAK,AAD3B,AAAI,AAAU,EAAM,QACY,OAEhC,AAAW,EAAO,GAAG,EAAK,GAAK,AAD/B,AAAI,AAAU,EAAM,QACgB,OAEpC,AAAW,EAAO,GAAG,EAAK,GAAK,AAD/B,AAAI,AAAU,EAAM,QACgB,OAEpC,AAAW,EAAO,GAAI,EAAK,GAAK,AADhC,AAAI,AAAU,EAAM,QACiB,OACrC,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,GAGA,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,EAAK,GAAK,AAD3B,AAAI,AAAU,EAAM,QACY,OAEhC,AAAW,EAAO,GAAG,EAAK,GAAK,AAD/B,AAAI,AAAU,EAAM,QACgB,OAEpC,AAAW,EAAO,GAAG,EAAK,GAAK,AAD/B,AAAI,AAAU,EAAM,QACgB,OAEpC,AAAW,EAAO,GAAI,EAAK,GAAK,AADhC,AAAI,AAAU,EAAM,QACiB,OACrC,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,GAGA,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,EAAK,GAAI,AAD1B,AAAI,AAAU,EAAM,QACW,OAE/B,AAAW,EAAO,GAAG,EAAK,GAAI,AAD9B,AAAI,AAAU,EAAM,QACe,OAEnC,AAAW,EAAO,GAAG,EAAK,GAAI,AAD9B,AAAI,AAAU,EAAM,QACe,OAEnC,AAAW,EAAO,GAAI,EAAK,GAAI,AAD/B,AAAI,AAAU,EAAM,QACgB,OACpC,EAAO,KAAI,EAAQ,KAAI,EAAK,WAQpC,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,IADD,EACkB,MAAT,gBAMpB,AAAI,EAAQ,KAAK,EACjB,AAAI,EAAM,GAAK,UAAQ,EAAO,GAAK,MACjC,AAAO,EAAM,EAAK,IAClB,EAEF,AAAI,EAAO,KACT,AAAI,AAAC,EAAM,GAAM,AAAC,EAAO,QAChB,EAAO,KACZ,AAAI,AAAC,KAAG,EACR,AAAE,OACQ,SAAV,EAA2B,WAAT,eAEb,EAAK,KACV,AAAW,EAAM,AAAU,QAC3B,EAAQ,KACR,EAAQ,KACR,EAAQ,YAGL,IACK,SAAV,EAA2B,WAAT,SAClB,AAAE,YAGJ,AAAI,AAAC,EAAM,GAAM,AAAC,EAAO,QAChB,AAAC,EAAO,GAAK,KAClB,AAAI,AAAC,KAAG,EACR,AAAU,EAAO,AAAE,QAAG,AAAS,EAAM,eAEhC,EAAK,KAEV,AAAW,EADX,EAAK,MACgB,AAAU,EAAM,gBAGlC,IAAG,AACE,EAAO,AAAE,QAAG,AAAS,EAAM,kBA3NvC,AAAQ,EAAM,EAAK,SA8RrB,AAAI,EAAM,KAAW,MACd,EAAK,OAAK,AAAS,KAAO,AAAS,YACxC,OAAK,OAAM,WAEsC,AAA5C,IAAI,AAAc,KAAM,AAAc,OAAM,MA7R1B,AAAT,EAAI,EAAI,SD0JxB,AAAI,EAAY,KAOd,AAAI,AAAO,AAAK,AAFhB,AAAe,AAAM,AAAC,AAAC,EAAY,UAAuB,KAD3C,KAGwB,KAAG,AACjC,IAGT,AAAU,EAAmB,MAExB,KAtFkD,AAAjC,EAAgB,SA+FxC,EAAY,KACZ,EAAY,UASZ,EADA,AAAW,UAEX,EAAa,KACb,EAAY,KACZ,EAAY,UAqEZ,IACA,MAEO,EAAO,KACZ,OACA,EAAQ,SAGH,KAnCkE,AAAlE,AAAC,AAAC,EAAM,GAAa,EAAkB,IAAW,AAAC,EAAK,IAAU,MAxG9B,AAA3B,EAAsB,SAgH8B,AAA7D,AAAC,AAAC,AAAkB,AAD3B,AAAQ,AAAC,EAAQ,GAAK,KACa,KAAO,AAAM,EAAQ,IAAM,GAAM,QAtCpE,AAFA,AAAW,OACX,AAAW,UAEX,EAAY,QAoB+D,AAApE,EAAW,AAAC,AAAC,EAAQ,AAAC,EAAK,IAAU,GAAM,EAAkB,UAyBpE,AAAgB,AADhB,AAAQ,AAAC,EAAQ,GAAK,KACE,OAEtB,AAAkB,IAAa,AAAM,EAAK,AAAC,EAAQ,wBA0B9C,EAAS,KAUd,AAAI,AAAC,AATL,AAAW,AAAa,EAAU,WAUhC,AAAY,IACZ,AAAU,AAAY,EAAE,cACxB,AAAU,AAAY,IAAe,IACrC,GAYF,AAAI,AAAC,AAAe,AADpB,AAAc,AAAa,EAAO,GAAG,cACS,AACrC,IAET,AAAU,AAAY,IAAe,IACrC,AAAU,AAAY,EAAE,cAOxB,AADA,AAAO,AAAC,EAAO,GAAK,OACL,AACQ,SAIlB,OA3GP,AAAI,AADJ,AAAW,OACC,KAAa,IACzB,AAAY,IACL,OAqHP,AAAI,WAAmC,EAOvC,AAAI,KAEF,AAAW,AAAC,EAAoB,QAChC,AAAU,EAAwB,KAClC,IACA,AAAI,AAAC,AAAe,UAAuB,AAClC,IAET,AAAU,MACV,AAAU,IAA+B,KAQ3C,AADA,AAAS,AAAmB,aAQrB,EAAc,KAQnB,AAAI,AAAC,AAAmB,OAAS,AACxB,IAQT,AAAI,AADJ,AAAM,AAA2B,AAAY,WAM3C,AAAI,EAAU,UAAgB,MAC5B,OACA,GAUF,AAAI,AAAC,AAAmB,EAAS,QAAI,AAC5B,IAET,AAAM,AAA2B,AAAY,SAO/C,AAAO,EAAK,EAAkB,MAE9B,AAAI,AAAC,AAAe,EADL,EAAS,KAAkB,EAAO,OAAgB,SAE/D,AAAU,AAAY,IAAS,IACxB,IAeT,AADA,AAAI,AAAa,EAAK,QACV,AACW,OAUhB,EAAS,KAGd,AAFA,AAAI,EAAI,GAAI,OAGZ,AACE,AAHF,SAIE,AAA8B,EAAI,GAAG,UAQzC,AAAa,EAAK,KACL,AAAN,QAGF,MCpboC,AAAkB,SD8b7D,AAAI,AAAC,KAAK,EAUV,AAAS,AAAmB,AAD5B,AAAM,iBAEN,AAAI,AAAa,EAAK,MAMtB,IAAO,IAOL,AAAqB,IAU6B,AAA9C,AAAgB,WAAM,EAAU,MAWpC,AAAY,AAA8B,AAAC,AAAC,EAAI,GAAK,GAAK,GAAG,MAC7D,AAAI,AAAC,EAAI,GAAK,KACd,YASF,AAAU,AAAY,IAAS,AAA8B,EAAG,SChf9B,AAAc,eDuDzB,QA6CQ,IACF","sourceRoot":"assemblyscript:///","sourceContents":["/**\r\n * Buddy Memory Allocator.\r\n * @module std/assembly/allocator/buddy\r\n *//***/\r\n\r\n/*\r\n  Copyright 2018 Evan Wallace\r\n\r\n  Permission is hereby granted, free of charge, to any person obtaining a copy\r\n  of this software and associated documentation files (the \"Software\"), to deal\r\n  in the Software without restriction, including without limitation the rights\r\n  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n  copies of the Software, and to permit persons to whom the Software is\r\n  furnished to do so, subject to the following conditions:\r\n\r\n  The above copyright notice and this permission notice shall be included in all\r\n  copies or substantial portions of the Software.\r\n\r\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n  SOFTWARE.\r\n\r\n*/// see: https://github.com/evanw/buddy-malloc\r\n\r\n/*\r\n * This file implements a buddy memory allocator, which is an allocator that\r\n * allocates memory within a fixed linear address range. It spans the address\r\n * range with a binary tree that tracks free space. Both \"malloc\" and \"free\"\r\n * are O(log N) time where N is the maximum possible number of allocations.\r\n *\r\n * The \"buddy\" term comes from how the tree is used. When memory is allocated,\r\n * nodes in the tree are split recursively until a node of the appropriate size\r\n * is reached. Every split results in two child nodes, each of which is the\r\n * buddy of the other. When a node is freed, the node and its buddy can be\r\n * merged again if the buddy is also free. This makes the memory available\r\n * for larger allocations again.\r\n */\r\n\r\n/*\r\n * Every allocation needs an 8-byte header to store the allocation size while\r\n * staying 8-byte aligned. The address returned by \"malloc\" is the address\r\n * right after this header (i.e. the size occupies the 8 bytes before the\r\n * returned address).\r\n */\r\nconst HEADER_SIZE: usize = 8;\r\n\r\n/*\r\n * The minimum allocation size is 16 bytes because we have an 8-byte header and\r\n * we need to stay 8-byte aligned.\r\n */\r\nconst MIN_ALLOC_LOG2: usize = 4;\r\nconst MIN_ALLOC: usize = 1 << MIN_ALLOC_LOG2;\r\n\r\n/*\r\n * The maximum allocation size is currently set to 2gb. This is the total size\r\n * of the heap. It's technically also the maximum allocation size because the\r\n * heap could consist of a single allocation of this size. But of course real\r\n * heaps will have multiple allocations, so the real maximum allocation limit\r\n * is at most 1gb.\r\n */\r\nconst MAX_ALLOC_LOG2: usize = 30; // 31;\r\nconst MAX_ALLOC: usize = 1 << MAX_ALLOC_LOG2;\r\n\r\n/*\r\n * Allocations are done in powers of two starting from MIN_ALLOC and ending at\r\n * MAX_ALLOC inclusive. Each allocation size has a bucket that stores the free\r\n * list for that allocation size.\r\n *\r\n * Given a bucket index, the size of the allocations in that bucket can be\r\n * found with \"(size_t)1 << (MAX_ALLOC_LOG2 - bucket)\".\r\n */\r\nconst BUCKET_COUNT: usize = MAX_ALLOC_LOG2 - MIN_ALLOC_LOG2 + 1;\r\n\r\n/*\r\n * Free lists are stored as circular doubly-linked lists. Every possible\r\n * allocation size has an associated free list that is threaded through all\r\n * currently free blocks of that size. That means MIN_ALLOC must be at least\r\n * \"sizeof(list_t)\". MIN_ALLOC is currently 16 bytes, so this will be true for\r\n * both 32-bit and 64-bit.\r\n */\r\n@unmanaged\r\nclass List {\r\n  prev: List;\r\n  next: List;\r\n  static readonly SIZE: usize = 2 * sizeof<usize>();\r\n}\r\n\r\n/*\r\n * Each bucket corresponds to a certain allocation size and stores a free list\r\n * for that size. The bucket at index 0 corresponds to an allocation size of\r\n * MAX_ALLOC (i.e. the whole address space).\r\n */\r\nvar BUCKETS_START: usize = HEAP_BASE;\r\nvar BUCKETS_END: usize = BUCKETS_START + BUCKET_COUNT * List.SIZE;\r\n\r\nfunction buckets$get(index: usize): List {\r\n  assert(index < BUCKET_COUNT);\r\n  return changetype<List>(BUCKETS_START + index * List.SIZE);\r\n}\r\n\r\n/*\r\n * We could initialize the allocator by giving it one free block the size of\r\n * the entire address space. However, this would cause us to instantly reserve\r\n * half of the entire address space on the first allocation, since the first\r\n * split would store a free list entry at the start of the right child of the\r\n * root. Instead, we have the tree start out small and grow the size of the\r\n * tree as we use more memory. The size of the tree is tracked by this value.\r\n */\r\nvar bucket_limit: usize;\r\n\r\n/*\r\n * This array represents a linearized binary tree of bits. Every possible\r\n * allocation larger than MIN_ALLOC has a node in this tree (and therefore a\r\n * bit in this array).\r\n *\r\n * Given the index for a node, lineraized binary trees allow you to traverse to\r\n * the parent node or the child nodes just by doing simple arithmetic on the\r\n * index:\r\n *\r\n * - Move to parent:         index = (index - 1) / 2;\r\n * - Move to left child:     index = index * 2 + 1;\r\n * - Move to right child:    index = index * 2 + 2;\r\n * - Move to sibling:        index = ((index - 1) ^ 1) + 1;\r\n *\r\n * Each node in this tree can be in one of several states:\r\n *\r\n * - UNUSED (both children are UNUSED)\r\n * - SPLIT (one child is UNUSED and the other child isn't)\r\n * - USED (neither children are UNUSED)\r\n *\r\n * These states take two bits to store. However, it turns out we have enough\r\n * information to distinguish between UNUSED and USED from context, so we only\r\n * need to store SPLIT or not, which only takes a single bit.\r\n *\r\n * Note that we don't need to store any nodes for allocations of size MIN_ALLOC\r\n * since we only ever care about parent nodes.\r\n */\r\nconst SPLIT_COUNT: usize = (1 << (BUCKET_COUNT - 1)) / 8;\r\nvar NODE_IS_SPLIT_START: usize = BUCKETS_END;\r\nvar NODE_IS_SPLIT_END: usize = NODE_IS_SPLIT_START + SPLIT_COUNT * sizeof<u8>();\r\n\r\nfunction node_is_split$get(index: usize): i32 {\r\n  assert(index < SPLIT_COUNT);\r\n  return load<u8>(NODE_IS_SPLIT_START + index);\r\n}\r\n\r\nfunction node_is_split$set(index: usize, state: i32): void {\r\n  assert(index < SPLIT_COUNT);\r\n  store<u8>(NODE_IS_SPLIT_START + index, state);\r\n}\r\n\r\n/*\r\n * This is the starting address of the address range for this allocator. Every\r\n * returned allocation will be an offset of this pointer from 0 to MAX_ALLOC.\r\n */\r\nvar base_ptr: usize;\r\n\r\n/*\r\n * This is the maximum address that has ever been used by the allocator. It's\r\n * used to know when to call \"brk\" to request more memory from the kernel.\r\n */\r\nvar max_ptr: usize;\r\n\r\n/*\r\n * Make sure all addresses before \"new_value\" are valid and can be used. Memory\r\n * is allocated in a 2gb address range but that memory is not reserved up\r\n * front. It's only reserved when it's needed by calling this function. This\r\n * will return false if the memory could not be reserved.\r\n */\r\nfunction update_max_ptr(new_value: usize): i32 {\r\n  if (new_value > max_ptr) {\r\n    // if (brk(new_value)) {\r\n    //   return 0;\r\n    // }\r\n    let oldPages = <i32>memory.size();\r\n    let newPages = <i32>(((new_value + 0xffff) & ~0xffff) >>> 16);\r\n    assert(newPages > oldPages);\r\n    if (memory.grow(newPages - oldPages) < 0) {\r\n      return 0;\r\n    }\r\n    // max_ptr = new_value;\r\n    max_ptr = <usize>newPages << 16;\r\n  }\r\n  return 1;\r\n}\r\n\r\n/*\r\n * Initialize a list to empty. Because these are circular lists, an \"empty\"\r\n * list is an entry where both links point to itself. This makes insertion\r\n * and removal simpler because they don't need any branches.\r\n */\r\nfunction list_init(list: List): void {\r\n  list.prev = list;\r\n  list.next = list;\r\n}\r\n\r\n/*\r\n * Append the provided entry to the end of the list. This assumes the entry\r\n * isn't in a list already because it overwrites the linked list pointers.\r\n */\r\nfunction list_push(list: List, entry: List): void {\r\n  var prev = list.prev;\r\n  entry.prev = prev;\r\n  entry.next = list;\r\n  prev.next = entry;\r\n  list.prev = entry;\r\n}\r\n\r\n/*\r\n * Remove the provided entry from whichever list it's currently in. This\r\n * assumes that the entry is in a list. You don't need to provide the list\r\n * because the lists are circular, so the list's pointers will automatically\r\n * be updated if the first or last entries are removed.\r\n */\r\nfunction list_remove(entry: List): void {\r\n  var prev = entry.prev;\r\n  var next = entry.next;\r\n  prev.next = next;\r\n  next.prev = prev;\r\n}\r\n\r\n/*\r\n * Remove and return the first entry in the list or NULL if the list is empty.\r\n */\r\nfunction list_pop(list: List): List | null {\r\n  var back = list.prev;\r\n  if (back == list) return null;\r\n  list_remove(back);\r\n  return back;\r\n}\r\n\r\n/*\r\n * This maps from the index of a node to the address of memory that node\r\n * represents. The bucket can be derived from the index using a loop but is\r\n * required to be provided here since having them means we can avoid the loop\r\n * and have this function return in constant time.\r\n */\r\nfunction ptr_for_node(index: usize, bucket: usize): usize {\r\n  return base_ptr + ((index - (1 << bucket) + 1) << (MAX_ALLOC_LOG2 - bucket));\r\n}\r\n\r\n/*\r\n * This maps from an address of memory to the node that represents that\r\n * address. There are often many nodes that all map to the same address, so\r\n * the bucket is needed to uniquely identify a node.\r\n */\r\nfunction node_for_ptr(ptr: usize, bucket: usize): usize {\r\n  return ((ptr - base_ptr) >> (MAX_ALLOC_LOG2 - bucket)) + (1 << bucket) - 1;\r\n}\r\n\r\n/*\r\n * Given the index of a node, this returns the \"is split\" flag of the parent.\r\n */\r\nfunction parent_is_split(index: usize): bool {\r\n  index = (index - 1) / 2;\r\n  return ((node_is_split$get(index / 8) >>> <i32>(index % 8)) & 1) == 1;\r\n}\r\n\r\n/*\r\n * Given the index of a node, this flips the \"is split\" flag of the parent.\r\n */\r\nfunction flip_parent_is_split(index: usize): void {\r\n  index = (index - 1) / 2;\r\n  var indexDiv8 = index / 8;\r\n  node_is_split$set(indexDiv8,\r\n    node_is_split$get(indexDiv8) ^ <i32>(1 << (index % 8))\r\n  );\r\n}\r\n\r\n/*\r\n * Given the requested size passed to \"malloc\", this function returns the index\r\n * of the smallest bucket that can fit that size.\r\n */\r\nfunction bucket_for_request(request: usize): usize {\r\n  var bucket = BUCKET_COUNT - 1;\r\n  var size = MIN_ALLOC;\r\n\r\n  while (size < request) {\r\n    bucket--;\r\n    size *= 2;\r\n  }\r\n\r\n  return bucket;\r\n}\r\n\r\n/*\r\n * The tree is always rooted at the current bucket limit. This call grows the\r\n * tree by repeatedly doubling it in size until the root lies at the provided\r\n * bucket index. Each doubling lowers the bucket limit by 1.\r\n */\r\nfunction lower_bucket_limit(bucket: usize): u32 {\r\n  while (bucket < bucket_limit) {\r\n    let root = node_for_ptr(base_ptr, bucket_limit);\r\n    let right_child: usize;\r\n\r\n    /*\r\n     * If the parent isn't SPLIT, that means the node at the current bucket\r\n     * limit is UNUSED and our address space is entirely free. In that case,\r\n     * clear the root free list, increase the bucket limit, and add a single\r\n     * block with the newly-expanded address space to the new root free list.\r\n     */\r\n    if (!parent_is_split(root)) {\r\n      list_remove(changetype<List>(base_ptr));\r\n      list_init(buckets$get(--bucket_limit));\r\n      list_push(buckets$get(bucket_limit), changetype<List>(base_ptr));\r\n      continue;\r\n    }\r\n\r\n    /*\r\n     * Otherwise, the tree is currently in use. Create a parent node for the\r\n     * current root node in the SPLIT state with a right child on the free\r\n     * list. Make sure to reserve the memory for the free list entry before\r\n     * writing to it. Note that we do not need to flip the \"is split\" flag for\r\n     * our current parent because it's already on (we know because we just\r\n     * checked it above).\r\n     */\r\n    right_child = ptr_for_node(root + 1, bucket_limit);\r\n    if (!update_max_ptr(right_child + List.SIZE)) {\r\n      return 0;\r\n    }\r\n    list_push(buckets$get(bucket_limit), changetype<List>(right_child));\r\n    list_init(buckets$get(--bucket_limit));\r\n\r\n    /*\r\n     * Set the grandparent's SPLIT flag so if we need to lower the bucket limit\r\n     * again, we'll know that the new root node we just added is in use.\r\n     */\r\n    root = (root - 1) / 2;\r\n    if (root != 0) {\r\n      flip_parent_is_split(root);\r\n    }\r\n  }\r\n\r\n  return 1;\r\n}\r\n\r\n@global\r\nexport function __memory_allocate(request: usize): usize {\r\n  var original_bucket: usize, bucket: usize;\r\n\r\n  /*\r\n   * Make sure it's possible for an allocation of this size to succeed. There's\r\n   * a hard-coded limit on the maximum allocation size because of the way this\r\n   * allocator works.\r\n   */\r\n  if (request > MAX_ALLOC - HEADER_SIZE) unreachable();\r\n\r\n  /*\r\n   * Initialize our global state if this is the first call to \"malloc\". At the\r\n   * beginning, the tree has a single node that represents the smallest\r\n   * possible allocation size. More memory will be reserved later as needed.\r\n   */\r\n  if (base_ptr == 0) {\r\n    // base_ptr = max_ptr = (uint8_t *)sbrk(0);\r\n    base_ptr = (NODE_IS_SPLIT_END + 7) & ~7; // must be aligned\r\n    max_ptr = <usize>memory.size() << 16; // must grow first\r\n    bucket_limit = BUCKET_COUNT - 1;\r\n    if (!update_max_ptr(base_ptr + List.SIZE)) {\r\n      return 0;\r\n    }\r\n    list_init(buckets$get(BUCKET_COUNT - 1));\r\n    list_push(buckets$get(BUCKET_COUNT - 1), changetype<List>(base_ptr));\r\n  }\r\n\r\n  /*\r\n   * Find the smallest bucket that will fit this request. This doesn't check\r\n   * that there's space for the request yet.\r\n   */\r\n  bucket = bucket_for_request(request + HEADER_SIZE);\r\n  original_bucket = bucket;\r\n\r\n  /*\r\n   * Search for a bucket with a non-empty free list that's as large or larger\r\n   * than what we need. If there isn't an exact match, we'll need to split a\r\n   * larger one to get a match.\r\n   */\r\n  while (bucket + 1 != 0) {\r\n    let size: usize, bytes_needed: usize, i: usize;\r\n    let ptr: usize;\r\n\r\n    /*\r\n     * We may need to grow the tree to be able to fit an allocation of this\r\n     * size. Try to grow the tree and stop here if we can't.\r\n     */\r\n    if (!lower_bucket_limit(bucket)) {\r\n      return 0;\r\n    }\r\n\r\n    /*\r\n     * Try to pop a block off the free list for this bucket. If the free list\r\n     * is empty, we're going to have to split a larger block instead.\r\n     */\r\n    ptr = changetype<usize>(list_pop(buckets$get(bucket)));\r\n    if (!ptr) {\r\n      /*\r\n       * If we're not at the root of the tree or it's impossible to grow the\r\n       * tree any more, continue on to the next bucket.\r\n       */\r\n      if (bucket != bucket_limit || bucket == 0) {\r\n        bucket--;\r\n        continue;\r\n      }\r\n\r\n      /*\r\n       * Otherwise, grow the tree one more level and then pop a block off the\r\n       * free list again. Since we know the root of the tree is used (because\r\n       * the free list was empty), this will add a parent above this node in\r\n       * the SPLIT state and then add the new right child node to the free list\r\n       * for this bucket. Popping the free list will give us this right child.\r\n       */\r\n      if (!lower_bucket_limit(bucket - 1)) {\r\n        return 0;\r\n      }\r\n      ptr = changetype<usize>(list_pop(buckets$get(bucket)));\r\n    }\r\n\r\n    /*\r\n     * Try to expand the address space first before going any further. If we\r\n     * have run out of space, put this block back on the free list and fail.\r\n     */\r\n    size = 1 << (MAX_ALLOC_LOG2 - bucket);\r\n    bytes_needed = bucket < original_bucket ? size / 2 + List.SIZE : size;\r\n    if (!update_max_ptr(ptr + bytes_needed)) {\r\n      list_push(buckets$get(bucket), changetype<List>(ptr));\r\n      return 0;\r\n    }\r\n\r\n    /*\r\n     * If we got a node off the free list, change the node from UNUSED to USED.\r\n     * This involves flipping our parent's \"is split\" bit because that bit is\r\n     * the exclusive-or of the UNUSED flags of both children, and our UNUSED\r\n     * flag (which isn't ever stored explicitly) has just changed.\r\n     *\r\n     * Note that we shouldn't ever need to flip the \"is split\" bit of our\r\n     * grandparent because we know our buddy is USED so it's impossible for our\r\n     * grandparent to be UNUSED (if our buddy chunk was UNUSED, our parent\r\n     * wouldn't ever have been split in the first place).\r\n     */\r\n    i = node_for_ptr(ptr, bucket);\r\n    if (i != 0) {\r\n      flip_parent_is_split(i);\r\n    }\r\n\r\n    /*\r\n     * If the node we got is larger than we need, split it down to the correct\r\n     * size and put the new unused child nodes on the free list in the\r\n     * corresponding bucket. This is done by repeatedly moving to the left\r\n     * child, splitting the parent, and then adding the right child to the free\r\n     * list.\r\n     */\r\n    while (bucket < original_bucket) {\r\n      i = i * 2 + 1;\r\n      bucket++;\r\n      flip_parent_is_split(i);\r\n      list_push(\r\n        buckets$get(bucket),\r\n        changetype<List>(ptr_for_node(i + 1, bucket))\r\n      );\r\n    }\r\n\r\n    /*\r\n     * Now that we have a memory address, write the block header (just the size\r\n     * of the allocation) and return the address immediately after the header.\r\n     */\r\n    store<usize>(ptr, request);\r\n    return ptr + HEADER_SIZE;\r\n  }\r\n\r\n  return 0;\r\n}\r\n\r\n@global\r\nexport function __memory_free(ptr: usize): void {\r\n  var bucket: usize, i: usize;\r\n\r\n  /*\r\n   * Ignore any attempts to free a NULL pointer.\r\n   */\r\n  if (!ptr) {\r\n    return;\r\n  }\r\n\r\n  /*\r\n   * We were given the address returned by \"malloc\" so get back to the actual\r\n   * address of the node by subtracting off the size of the block header. Then\r\n   * look up the index of the node corresponding to this address.\r\n   */\r\n  ptr = ptr - HEADER_SIZE;\r\n  bucket = bucket_for_request(load<usize>(ptr) + HEADER_SIZE);\r\n  i = node_for_ptr(ptr, bucket);\r\n\r\n  /*\r\n   * Traverse up to the root node, flipping USED blocks to UNUSED and merging\r\n   * UNUSED buddies together into a single UNUSED parent.\r\n   */\r\n  while (i != 0) {\r\n    /*\r\n     * Change this node from UNUSED to USED. This involves flipping our\r\n     * parent's \"is split\" bit because that bit is the exclusive-or of the\r\n     * UNUSED flags of both children, and our UNUSED flag (which isn't ever\r\n     * stored explicitly) has just changed.\r\n     */\r\n    flip_parent_is_split(i);\r\n\r\n    /*\r\n     * If the parent is now SPLIT, that means our buddy is USED, so don't merge\r\n     * with it. Instead, stop the iteration here and add ourselves to the free\r\n     * list for our bucket.\r\n     *\r\n     * Also stop here if we're at the current root node, even if that root node\r\n     * is now UNUSED. Root nodes don't have a buddy so we can't merge with one.\r\n     */\r\n    if (parent_is_split(i) || bucket == bucket_limit) {\r\n      break;\r\n    }\r\n\r\n    /*\r\n     * If we get here, we know our buddy is UNUSED. In this case we should\r\n     * merge with that buddy and continue traversing up to the root node. We\r\n     * need to remove the buddy from its free list here but we don't need to\r\n     * add the merged parent to its free list yet. That will be done once after\r\n     * this loop is finished.\r\n     */\r\n    list_remove(changetype<List>(ptr_for_node(((i - 1) ^ 1) + 1, bucket)));\r\n    i = (i - 1) / 2;\r\n    bucket--;\r\n  }\r\n\r\n  /*\r\n   * Add ourselves to the free list for our bucket. We add to the back of the\r\n   * list because \"malloc\" takes from the back of the list and we want a \"free\"\r\n   * followed by a \"malloc\" of the same size to ideally use the same address\r\n   * for better memory locality.\r\n   */\r\n  list_push(buckets$get(bucket), changetype<List>(ptr_for_node(i, bucket)));\r\n}\r\n\r\n@global\r\nexport function __memory_reset(): void {\r\n  unreachable();\r\n}\r\n","export namespace memory {\r\n\r\n  @builtin\r\n  export declare function size(): i32;\r\n\r\n  @builtin\r\n  export declare function grow(pages: i32): i32;\r\n\r\n  export function fill(dest: usize, c: u8, n: usize): void { // see: musl/src/string/memset\r\n    if (isDefined(__memory_fill)) { __memory_fill(dest, c, n); return; } // tslint:disable-line\r\n    memset(dest, c, n);\r\n  }\r\n\r\n  export function copy(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memmove.c\r\n    if (isDefined(__memory_copy)) { __memory_copy(dest, src, n); return; } // tslint:disable-line\r\n    memmove(dest, src, n);\r\n  }\r\n\r\n  export function compare(vl: usize, vr: usize, n: usize): i32 { // see: musl/src/string/memcmp.c\r\n    if (isDefined(__memory_compare)) return __memory_compare(vl, vr, n); // tslint:disable-line\r\n    return memcmp(vl, vr, n);\r\n  }\r\n\r\n  // Passive segments\r\n\r\n  // export function init(segmentIndex: u32, srcOffset: usize, dstOffset: usize, n: usize): void {\r\n  //   __memory_init(segmentIndex, srcOffset, dstOffset);\r\n  // }\r\n\r\n  // export function drop(segmentIndex: u32): void {\r\n  //   __memory_drop(segmentIndex);\r\n  // }\r\n\r\n  // Allocator\r\n\r\n  export function allocate(size: usize): usize {\r\n    if (isDefined(__memory_allocate)) return __memory_allocate(size); // tslint:disable-line\r\n    WARNING(\"Calling 'memory.allocate' requires a memory manager to be present.\");\r\n    return <usize>unreachable();\r\n  }\r\n\r\n  export function free(ptr: usize): void {\r\n    if (isDefined(__memory_free)) { __memory_free(ptr); return; } // tslint:disable-line\r\n    WARNING(\"Calling 'memory.free' requires a memory manager to be present.\");\r\n    unreachable();\r\n  }\r\n\r\n  export function reset(): void {\r\n    if (isDefined(__memory_reset)) { __memory_reset(); return; } // tslint:disable-line\r\n    unreachable();\r\n  }\r\n}\r\n\r\n// this function will go away once `memory.copy` becomes an intrinsic\r\nfunction memcpy(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memcpy.c\r\n  var w: u32, x: u32;\r\n\r\n  // copy 1 byte each until src is aligned to 4 bytes\r\n  while (n && (src & 3)) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n    n--;\r\n  }\r\n\r\n  // if dst is aligned to 4 bytes as well, copy 4 bytes each\r\n  if ((dest & 3) == 0) {\r\n    while (n >= 16) {\r\n      store<u32>(dest     , load<u32>(src     ));\r\n      store<u32>(dest +  4, load<u32>(src +  4));\r\n      store<u32>(dest +  8, load<u32>(src +  8));\r\n      store<u32>(dest + 12, load<u32>(src + 12));\r\n      src += 16; dest += 16; n -= 16;\r\n    }\r\n    if (n & 8) {\r\n      store<u32>(dest    , load<u32>(src    ));\r\n      store<u32>(dest + 4, load<u32>(src + 4));\r\n      dest += 8; src += 8;\r\n    }\r\n    if (n & 4) {\r\n      store<u32>(dest, load<u32>(src));\r\n      dest += 4; src += 4;\r\n    }\r\n    if (n & 2) { // drop to 2 bytes each\r\n      store<u16>(dest, load<u16>(src));\r\n      dest += 2; src += 2;\r\n    }\r\n    if (n & 1) { // drop to 1 byte\r\n      store<u8>(dest++, load<u8>(src++));\r\n    }\r\n    return;\r\n  }\r\n\r\n  // if dst is not aligned to 4 bytes, use alternating shifts to copy 4 bytes each\r\n  // doing shifts if faster when copying enough bytes (here: 32 or more)\r\n  if (n >= 32) {\r\n    switch (dest & 3) {\r\n      // known to be != 0\r\n      case 1: {\r\n        w = load<u32>(src);\r\n        store<u8>(dest++, load<u8>(src++));\r\n        store<u8>(dest++, load<u8>(src++));\r\n        store<u8>(dest++, load<u8>(src++));\r\n        n -= 3;\r\n        while (n >= 17) {\r\n          x = load<u32>(src + 1);\r\n          store<u32>(dest, w >> 24 | x << 8);\r\n          w = load<u32>(src + 5);\r\n          store<u32>(dest + 4, x >> 24 | w << 8);\r\n          x = load<u32>(src + 9);\r\n          store<u32>(dest + 8, w >> 24 | x << 8);\r\n          w = load<u32>(src + 13);\r\n          store<u32>(dest + 12, x >> 24 | w << 8);\r\n          src += 16; dest += 16; n -= 16;\r\n        }\r\n        break;\r\n      }\r\n      case 2: {\r\n        w = load<u32>(src);\r\n        store<u8>(dest++, load<u8>(src++));\r\n        store<u8>(dest++, load<u8>(src++));\r\n        n -= 2;\r\n        while (n >= 18) {\r\n          x = load<u32>(src + 2);\r\n          store<u32>(dest, w >> 16 | x << 16);\r\n          w = load<u32>(src + 6);\r\n          store<u32>(dest + 4, x >> 16 | w << 16);\r\n          x = load<u32>(src + 10);\r\n          store<u32>(dest + 8, w >> 16 | x << 16);\r\n          w = load<u32>(src + 14);\r\n          store<u32>(dest + 12, x >> 16 | w << 16);\r\n          src += 16; dest += 16; n -= 16;\r\n        }\r\n        break;\r\n      }\r\n      case 3: {\r\n        w = load<u32>(src);\r\n        store<u8>(dest++, load<u8>(src++));\r\n        n -= 1;\r\n        while (n >= 19) {\r\n          x = load<u32>(src + 3);\r\n          store<u32>(dest, w >> 8 | x << 24);\r\n          w = load<u32>(src + 7);\r\n          store<u32>(dest + 4, x >> 8 | w << 24);\r\n          x = load<u32>(src + 11);\r\n          store<u32>(dest + 8, w >> 8 | x << 24);\r\n          w = load<u32>(src + 15);\r\n          store<u32>(dest + 12, x >> 8 | w << 24);\r\n          src += 16; dest += 16; n -= 16;\r\n        }\r\n        break;\r\n      }\r\n    }\r\n  }\r\n\r\n  // copy remaining bytes one by one\r\n  if (n & 16) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n  }\r\n  if (n & 8) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n  }\r\n  if (n & 4) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n  }\r\n  if (n & 2) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n    store<u8>(dest++, load<u8>(src++));\r\n  }\r\n  if (n & 1) {\r\n    store<u8>(dest++, load<u8>(src++));\r\n  }\r\n}\r\n\r\n// this function will go away once `memory.copy` becomes an intrinsic\r\nfunction memmove(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memmove.c\r\n  if (dest == src) return;\r\n  if (src + n <= dest || dest + n <= src) {\r\n    memcpy(dest, src, n);\r\n    return;\r\n  }\r\n  if (dest < src) {\r\n    if ((src & 7) == (dest & 7)) {\r\n      while (dest & 7) {\r\n        if (!n) return;\r\n        --n;\r\n        store<u8>(dest++, load<u8>(src++));\r\n      }\r\n      while (n >= 8) {\r\n        store<u64>(dest, load<u64>(src));\r\n        n    -= 8;\r\n        dest += 8;\r\n        src  += 8;\r\n      }\r\n    }\r\n    while (n) {\r\n      store<u8>(dest++, load<u8>(src++));\r\n      --n;\r\n    }\r\n  } else {\r\n    if ((src & 7) == (dest & 7)) {\r\n      while ((dest + n) & 7) {\r\n        if (!n) return;\r\n        store<u8>(dest + --n, load<u8>(src + n));\r\n      }\r\n      while (n >= 8) {\r\n        n -= 8;\r\n        store<u64>(dest + n, load<u64>(src + n));\r\n      }\r\n    }\r\n    while (n) {\r\n      store<u8>(dest + --n, load<u8>(src + n));\r\n    }\r\n  }\r\n}\r\n\r\n// this function will go away once `memory.fill` becomes an intrinsic\r\nfunction memset(dest: usize, c: u8, n: usize): void { // see: musl/src/string/memset\r\n\r\n  // fill head and tail with minimal branching\r\n  if (!n) return;\r\n  store<u8>(dest, c);\r\n  store<u8>(dest + n - 1, c);\r\n  if (n <= 2) return;\r\n\r\n  store<u8>(dest + 1, c);\r\n  store<u8>(dest + 2, c);\r\n  store<u8>(dest + n - 2, c);\r\n  store<u8>(dest + n - 3, c);\r\n  if (n <= 6) return;\r\n  store<u8>(dest + 3, c);\r\n  store<u8>(dest + n - 4, c);\r\n  if (n <= 8) return;\r\n\r\n  // advance pointer to align it at 4-byte boundary\r\n  var k: usize = -dest & 3;\r\n  dest += k;\r\n  n -= k;\r\n  n &= -4;\r\n\r\n  var c32: u32 = <u32>-1 / 255 * c;\r\n\r\n  // fill head/tail up to 28 bytes each in preparation\r\n  store<u32>(dest, c32);\r\n  store<u32>(dest + n - 4, c32);\r\n  if (n <= 8) return;\r\n  store<u32>(dest + 4, c32);\r\n  store<u32>(dest + 8, c32);\r\n  store<u32>(dest + n - 12, c32);\r\n  store<u32>(dest + n - 8, c32);\r\n  if (n <= 24) return;\r\n  store<u32>(dest + 12, c32);\r\n  store<u32>(dest + 16, c32);\r\n  store<u32>(dest + 20, c32);\r\n  store<u32>(dest + 24, c32);\r\n  store<u32>(dest + n - 28, c32);\r\n  store<u32>(dest + n - 24, c32);\r\n  store<u32>(dest + n - 20, c32);\r\n  store<u32>(dest + n - 16, c32);\r\n\r\n  // align to a multiple of 8\r\n  k = 24 + (dest & 4);\r\n  dest += k;\r\n  n -= k;\r\n\r\n  // copy 32 bytes each\r\n  var c64: u64 = <u64>c32 | (<u64>c32 << 32);\r\n  while (n >= 32) {\r\n    store<u64>(dest, c64);\r\n    store<u64>(dest + 8, c64);\r\n    store<u64>(dest + 16, c64);\r\n    store<u64>(dest + 24, c64);\r\n    n -= 32;\r\n    dest += 32;\r\n  }\r\n}\r\n\r\nfunction memcmp(vl: usize, vr: usize, n: usize): i32 { // see: musl/src/string/memcmp.c\r\n  if (vl == vr) return 0;\r\n  while (n != 0 && load<u8>(vl) == load<u8>(vr)) {\r\n    n--; vl++; vr++;\r\n  }\r\n  return n ? <i32>load<u8>(vl) - <i32>load<u8>(vr) : 0;\r\n}\r\n"]}